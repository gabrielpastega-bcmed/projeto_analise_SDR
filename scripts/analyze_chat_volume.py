"""
Script para analisar volume de chats por semana e perÃ­odo.

Ajuda a determinar a melhor estratÃ©gia de deduplicaÃ§Ã£o.
"""

import os
import sys
from datetime import datetime, timedelta

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from google.cloud import bigquery

load_dotenv()


def analyze_chat_volume():
    """Analisa volume de chats para determinar melhor estratÃ©gia."""

    client = bigquery.Client()

    project_id = os.getenv("BIGQUERY_PROJECT_ID")
    dataset_id = os.getenv("BIGQUERY_DATASET")
    table_name = "chats"

    table_id = f"{project_id}.{dataset_id}.{table_name}"

    print("\n" + "=" * 60)
    print("ANALISE DE VOLUME DE CHATS")
    print("=" * 60 + "\n")

    # Query 1: Total de chats
    query_total = f"""
    SELECT COUNT(*) as total
    FROM `{table_id}`
    """

    result = client.query(query_total).result()
    total_chats = list(result)[0].total
    print(f"ðŸ“Š Total de chats (all time): {total_chats:,}")

    # Query 2: Chats por semana (ultimas 8 semanas)
    query_weekly = f"""
    WITH weekly_stats AS (
        SELECT 
            DATE_TRUNC(CAST(firstMessageDate AS DATE), WEEK(MONDAY)) as week_start,
            COUNT(*) as chat_count
        FROM `{table_id}`
        WHERE firstMessageDate >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 8 WEEK)
        GROUP BY week_start
        ORDER BY week_start DESC
    )
    SELECT 
        week_start,
        chat_count,
        AVG(chat_count) OVER() as avg_per_week
    FROM weekly_stats
    """

    print("\nðŸ“… Chats por Semana (ultimas 8 semanas):")
    print("-" * 60)

    results = client.query(query_weekly).result()
    weekly_data = []

    for row in results:
        weekly_data.append(
            {"week": row.week_start, "count": row.chat_count, "avg": row.avg_per_week}
        )
        print(f"  {row.week_start}: {row.chat_count:,} chats")

    if weekly_data:
        avg = weekly_data[0]["avg"]
        print(f"\n  MÃ©dia semanal: {avg:,.0f} chats/semana")

        # Query 3: Chats por dia (ultima semana)
        query_daily = f"""
        SELECT 
            CAST(firstMessageDate AS DATE) as day,
            COUNT(*) as chat_count
        FROM `{table_id}`
        WHERE firstMessageDate >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
        GROUP BY day
        ORDER BY day DESC
        """

        print("\nðŸ“† Chats por Dia (ultima semana):")
        print("-" * 60)

        daily_results = client.query(query_daily).result()
        daily_counts = []

        for row in daily_results:
            daily_counts.append(row.chat_count)
            print(f"  {row.day}: {row.chat_count:,} chats")

        if daily_counts:
            avg_daily = sum(daily_counts) / len(daily_counts)
            print(f"\n  MÃ©dia diÃ¡ria: {avg_daily:,.0f} chats/dia")

        # Analise de estratÃ©gia
        print("\n" + "=" * 60)
        print("ðŸ’¡ ANALISE DE ESTRATÃ‰GIA")
        print("=" * 60 + "\n")

        if avg < 100:
            strategy = "BATCH-BASED (Atual)"
            reason = "Volume baixo, batch otimizado Ã© ideal"
        elif avg < 1000:
            strategy = "BATCH-BASED (Recomendado)"
            reason = "Volume mÃ©dio, batch otimizado funciona bem"
        elif avg < 5000:
            strategy = "HÃBRIDO"
            reason = "Volume alto, considere batch para novos + index para histÃ³rico"
        else:
            strategy = "INDEX-BASED"
            reason = "Volume muito alto, considere index separado de IDs analisados"

        print(f"Volume mÃ©dio semanal: {avg:,.0f} chats")
        print(f"Estrategia recomendada: {strategy}")
        print(f"Razao: {reason}")

        print("\nðŸ“Š ComparaÃ§Ã£o de Abordagens:")
        print("-" * 60)

        # Batch-based
        batch_size = 500
        num_batches = int(avg / batch_size) + 1
        print(f"\n1. BATCH-BASED (atual otimizado):")
        print(f"   - Batches por semana: {num_batches}")
        print(f"   - IDs por query: {batch_size} (maximo)")
        print(f"   - Queries total: {num_batches}")
        print(f"   - Custo estimado: BAIXO")
        print(f"   - Complexidade: BAIXA")

        # Week-based
        print(f"\n2. WEEK-BASED (busca todos da semana):")
        print(f"   - IDs por query: {avg:,.0f}")
        print(f"   - Queries total: 1")
        print(f"   - Custo estimado: {'MÃ‰DIO' if avg < 5000 else 'ALTO'}")
        print(f"   - Complexidade: BAIXA")

        # Bloom filter / Index
        print(f"\n3. BLOOM FILTER / EXTERNAL INDEX:")
        print(f"   - IDs em memÃ³ria: {avg:,.0f}")
        print(f"   - Memory footprint: ~{avg * 50 / 1024:.1f} KB")
        print(f"   - Queries total: 0 (apos carregar)")
        print(f"   - Custo estimado: {'BAIXO' if avg < 10000 else 'MÃ‰DIO'}")
        print(f"   - Complexidade: ALTA")

        print("\n" + "=" * 60)
        print("RECOMENDACOES:")
        print("=" * 60)

        if avg < 1000:
            print(
                """
âœ… BATCH-BASED Ã© a melhor opÃ§Ã£o:
   - Volume estÃ¡ dentro do ideal (< 1000/semana)
   - Query otimizada com WHERE IN (...) Ã© muito rÃ¡pida
   - Baixa complexidade de implementaÃ§Ã£o
   - EscalÃ¡vel atÃ© ~5000 chats/semana

ðŸ’¡ PrÃ³ximos passos:
   1. Implementar batch-based otimizado
   2. Monitorar performance
   3. Reavaliar se volume crescer >5000/semana
            """
            )
        elif avg < 5000:
            print(
                """
âš ï¸ BATCH-BASED funciona, mas considere otimizaÃ§Ãµes:
   - Volume estÃ¡ alto (1000-5000/semana)
   - Batch-based ainda Ã© eficiente
   - Considere cache de IDs analisados em memÃ³ria
   - Monitore query performance

ðŸ’¡ PrÃ³ximos passos:
   1. Implementar batch-based
   2. Adicionar cache opcional (Redis)
   3. Reavaliar se volume crescer >5000/semana
            """
            )
        else:
            print(
                """
ðŸ”¥ Volume ALTO - Considere abordagem hÃ­brida:
   - Volume estÃ¡ muito alto (>5000/semana)
   - Batch-based pode ficar lento
   - Recomendo uma das seguintes:
     a) Tabela auxiliar com IDs analisados (index otimizado)
     b) Bloom filter em memÃ³ria
     c) Cache distribuÃ­do (Redis)

ðŸ’¡ PrÃ³ximos passos:
   1. Implementar batch-based como MVP
   2. Monitorar performance real
   3. Migrar para soluÃ§Ã£o escalÃ¡vel se necessÃ¡rio
            """
            )


if __name__ == "__main__":
    analyze_chat_volume()
